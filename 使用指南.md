
# 轮式四足机器人训练和评估使用指南

本指南将帮助您快速开始使用轮式四足机器人训练和评估系统。

## 快速开始

### 1. 训练模型

使用以下命令开始训练：

```bash
python simple_train.py -e wheel-quadruped-walking -B 10 --max_iterations 7000
```

参数说明：

- `-e` 或 `--exp_name`: 实验名称，用于保存日志和模型
- `-B` 或 `--num_envs`: 并行环境数量
- `--max_iterations`: 最大训练迭代次数

训练过程中，模型和日志将保存在 `logs/wheel-quadruped-walking/` 目录下。

### 2. 评估模型

训练完成后，使用以下命令评估模型：

```bash
python simple_eval.py -e wheel-quadruped-walking --ckpt 1300
```

参数说明：

- `-e` 或 `--exp_name`: 实验名称
- `--ckpt`: 要加载的检查点编号

评估过程中，可以使用游戏手柄控制机器人。

## 环境配置

### 环境配置 (env_cfg)

环境配置包含机器人物理参数和控制参数，例如：

- 机器人 URDF 文件路径
- 关节名称和类型
- 关节限制和安全力
- PD 控制器参数
- 终止条件等

### 观测配置 (obs_cfg)

观测配置定义了提供给强化学习算法的状态信息，包括：

- 观测空间维度
- 历史观测长度
- 观测缩放因子
- 噪声参数

### 奖励配置 (reward_cfg)

奖励配置定义了各种奖励组件及其权重，包括：

- 速度跟踪奖励
- 姿态控制奖励
- 动作正则化惩罚
- 步态质量奖励
- 对称性奖励
- 约束违反惩罚等

### 命令配置 (command_cfg)

命令配置定义了机器人需要跟踪的命令范围，包括：

- 线速度 X 轴范围
- 线速度 Y 轴范围
- 角速度范围
- 腿长范围等

### 课程学习配置 (curriculum_cfg)

课程学习配置定义了训练难度如何逐步增加，包括：

- 速度误差阈值
- 课程学习步长
- 阻尼下降参数等

### 域随机化配置 (domain_rand_cfg)

域随机化配置定义了训练过程中随机化的参数，包括：

- 摩擦系数范围
- 质量偏移范围
- 质心偏移范围
- PD 控制器参数范围等

### 地形配置 (terrain_cfg)

地形配置定义了训练和评估中使用的地形，包括：

- 地形类型
- 重生点
- 地形缩放参数等

## 高级用法

### 使用 ROS2

如果需要与 ROS2 集成，可以使用以下脚本：

```bash
# 训练
python wheel_legged_train_ros2.py -e wheel-quadruped-walking -B 1024 --max_iterations 7000 --use_ros2

# 评估
python wheel_legged_eval_ros2.py -e wheel-quadruped-walking --ckpt 1300 --use_ros2
```

### 自定义配置

可以通过修改 `simple_train.py` 中的 `get_cfgs()` 函数来自定义环境、观测、奖励等配置。

## 故障排除

1. **CUDA 内存不足**：减少并行环境数量 (`-B` 参数)
2. **训练不收敛**：调整奖励权重或学习率
3. **评估时机器人不稳定**：检查模型是否正确加载，或尝试使用不同的检查点

## 监控训练进度

使用 TensorBoard 监控训练进度：

```bash
tensorboard --logdir logs/
```

## 导出模型

将训练好的模型导出为 ONNX 格式：

```bash
python onnx/pt2onnx.py
```
